---
title: "Agentic AI's OODA Loop Problem"
date: "2025-10-16"
publication: "IEEE Security & Privacy"
url: "https://www.schneier.com/essays/archives/2025/10/agentic-ais-ooda-loop-problem.html"
authors: "Barath Raghavan, Bruce Schneier"
---

The OODA loop (Observe, Orient, Decide, Act) framework for AI agents faces fundamental security challenges. Web-enabled LLMs query adversary-controlled sources mid-operation. Four critical security issues: far-reaching effects of poisoned training data, temporal asymmetry (attackers poison data years before exploitation), persistent state accumulating compromises, and compounded agent risks from nested OODA loops. The fundamental problem: AI compresses reality into model-legible forms, and adversaries attack the "map" rather than the territory. Security trilemma: fast, smart, and secure — pick any two. The vulnerability is not a defect; it is the feature working correctly. Attack is indistinguishable from normal operation because it uses the system's native language. We need "semantic integrity" — verifying interpretation and context, not just data and content. Integrity is not a feature to add but an architecture to choose.
