---
title: "AI and Trust"
date: "2023-12-01"
publication: "Harvard Kennedy School Belfer Center"
url: "https://www.schneier.com/essays/archives/2023/12/ai-and-trust.html"
authors: "Bruce Schneier"
---

Schneier distinguishes between interpersonal trust (personal relationships based on character) and social trust (reliability with strangers through laws and security). A critical error is treating corporations as friends rather than services — corporations are "precisely as immoral as the law and their reputations let them get away with." AI will amplify this error because: (1) Natural language interfaces cause us to ascribe human characteristics to AIs, making hidden agendas easier to conceal, and (2) Personal AI assistants require constant access to intimate user information, triggering friendship thinking despite being corporate profit-maximizing systems.

Beyond the friendship confusion, trusting untrustworthy AI risks outright fraud, mistaken expertise (confidence masking ignorance), incompetency, inconsistency, and illegality.

Markets won't provide trustworthy AI. Surveillance capitalism's incentives overwhelm ethical considerations. Government must establish social trust mechanisms: AI transparency laws, safety regulations, trustworthiness enforcement, and fiduciary responsibility. Rather than regulating AIs directly, regulations should target the humans and corporations controlling them.

Schneier calls for publicly-owned AI systems built by academia, nonprofits, or government — with political accountability, transparency, public responsiveness, universal access, and foundation for free-market innovation.

The fundamental conclusion: either government ensures trustworthy AI systems, or corporations will exploit the friend-service confusion for profit.
